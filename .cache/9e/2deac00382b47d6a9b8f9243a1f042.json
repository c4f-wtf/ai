{"id":"src/scenarios/templates/tictactoe-qtable.js","dependencies":[{"name":"/home/menzi/www/c4f.wtf/ai/package.json","includedInParent":true,"mtime":1574075114495}],"generated":{"js":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = exports.TicTacToeQTable = void 0;\nvar TicTacToeQTable = {\n  name: 'TicTacToe - Example Q-Table',\n  files: [{\n    name: 'index.js',\n    content: \"include('qtable.js');\\ninclude('train.js');\\n\\n\\nlet qtable = new QTable();\\n\\n\\nasync function init(){\\n    console.log('loading qtable');\\n    await qtable.load();\\n}\\n\\nasync function update(state, actions){\\n    const action = qtable.getBestValidAction(state);\\n    return action;\\n}\\n\\nasync function finish(state, score){\\n    console.log('final state: ', state);\\n    console.log('score: ', score);\\n}\"\n  }, {\n    name: 'qtable.js',\n    content: \"class QTable{\\n    constructor(initialValue = 0){\\n        this._data = new Map();\\n        this._initialValue = initialValue;\\n    }\\n    \\n    stateToKey(state){\\n        return state.board.flat().reduce(\\n                (a,c,i) => a + c * 10**(8-i)\\n            , 0);\\n    }\\n    \\n    idToAction(id){\\n        return {\\n            type: \\\"PLACE\\\",\\n            row: Math.floor(id / 3),\\n            col: id % 3,\\n            player: Player.Computer,\\n        }\\n    }\\n    \\n    actionToId(action){\\n        return action.row*3 + action.col;\\n    }\\n    \\n    set(state, action, value){\\n        const key = this.stateToKey(state);\\n        const actionId = this.actionToId(action);\\n        if(this._data.has(key)){\\n            this._data.get(key)[actionId] = value;\\n        }\\n        else{\\n            const cols = new Array(9).fill(this._initialValue);\\n            cols[actionId] = value;\\n            this._data.set(key, cols);\\n        }\\n    }\\n    \\n    get(state, action = undefined){\\n        const key = this.stateToKey(state);\\n        if(!this._data.has(key)){\\n            if(action === undefined)\\n                return new Array(9).fill(this._initialValue);\\n            else\\n                return this._initialValue;\\n        }\\n        if(action === undefined){ // return full row\\n            return this._data.get(key);\\n        }\\n        const actionId = this.actionToId(action);\\n        return this._data.get(key)[actionId];\\n    }\\n    \\n    getBestValidAction(state){\\n        const actions = this.get(state).map((x,i) => [i, x]);\\n        actions.sort((a,b) => b[1] - a[1]);\\n    \\n        let bestAction;\\n        for(let i = 0; i < actions.length; i++){\\n            bestAction = this.idToAction(actions[i][0]);\\n            if(validAction(state, bestAction))\\n                break;\\n        }\\n        \\n        return bestAction;\\n    }\\n    \\n    async store(name = 'qtable'){\\n        await storeJson(name, this._data);\\n    }\\n    \\n    async load(name = 'qtable'){\\n        try{\\n            this._data = await loadJson(name);\\n        }\\n        catch(e){\\n            console.warn(\\\"no file to load!\\\");\\n        }\\n    }\\n}\"\n  }, {\n    name: 'train.js',\n    content: \"async function trainInit(){\\n    qtable = new QTable(0);\\n    return 10; // update iterations\\n}\\n\\nasync function trainUpdate(iteration){\\n    const alpha = 0.4; // learning rate\\n    const gamma = 0.8; // discount factor\\n    const episodes = 5000;\\n    const epsilonStart = 1.0 / (iteration/2+1); // reduce random moves with iterations\\n    const epsilonCoverage = 0.8; // no random moves after 80% of episodes\\n    const epsilonDecline = epsilonStart / (episodes * epsilonCoverage);\\n    \\n    console.log(`training episodes: ${episodes*iteration} - ${episodes*(iteration+1)}`);\\n    \\n    let epsilon = epsilonStart;\\n    for(let episode = 0; episode < episodes; episode++){\\n        let state = {\\n            board: [[0,0,0],[0,0,0],[0,0,0]],\\n            player: Player.Human,\\n        }\\n        \\n        // player starts -> random move\\n        let playerActions = getActions(state);\\n        let actionId = Math.round(Math.random()*(playerActions.length-1));\\n        let playerAction = playerActions[actionId];\\n        state = performAction(state, playerAction);\\n        \\n        for(let move = 0; move < 5; move++){\\n            // computer turn\\n            let computerAction;\\n            if(Math.random() < epsilon){ // explore\\n                const computerActions = getActions(state);\\n                let actionId = Math.round(Math.random()*(computerActions.length-1));\\n                computerAction = computerActions[actionId];\\n            }\\n            else{ // use qtable to get best move\\n                const actions = qtable.get(state);\\n                computerAction = qtable.getBestValidAction(state, 0);\\n            }\\n            newState = performAction(state, computerAction);\\n            if(getWinner(newState) != Player.None){\\n                const score = getScore(newState, Player.Computer);\\n                qtable.set(state, computerAction, score);\\n                break; // terminate match\\n            }\\n            oldState = {...state};\\n            state = newState;\\n            \\n            // player turn -> random move\\n            playerActions = getActions(state);\\n            actionId = Math.round(Math.random()*(playerActions.length-1));\\n            playerAction = playerActions[actionId];\\n            newState = performAction(state, playerAction);\\n            \\n            if(getWinner(newState) != Player.None){\\n                const reward = getScore(newState, Player.Computer);\\n                const oldScore = qtable.get(oldState, computerAction);\\n                const newScore = (1-alpha)*oldScore + alpha*reward ;\\n                qtable.set(oldState, computerAction, newScore);\\n                break; // terminate match\\n            }\\n            else{\\n                const reward = getScore(newState, Player.Computer);\\n                const oldScore = qtable.get(oldState, computerAction);\\n                const bestNewScore = Math.max(...qtable.get(newState));\\n                const newScore = (1-alpha)*oldScore + alpha*(reward + gamma*bestNewScore);\\n                qtable.set(oldState, computerAction, newScore);\\n                state = newState;\\n            }\\n        }\\n        epsilon -= epsilonDecline;\\n    }\\n}\\n\\nasync function trainFinish(){\\n    await qtable.store();\\n    console.log('training finished!');\\n}\"\n  }]\n};\nexports.TicTacToeQTable = TicTacToeQTable;\nvar _default = TicTacToeQTable;\nexports.default = _default;"},"sourceMaps":{"js":{"mappings":[{"generated":{"line":7,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":1,"column":7}},{"name":"TicTacToeQTable","generated":{"line":7,"column":4},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":1,"column":13}},{"generated":{"line":7,"column":19},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":1,"column":28}},{"generated":{"line":7,"column":22},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":1,"column":31}},{"name":"name","generated":{"line":8,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":2,"column":4}},{"name":"name","generated":{"line":8,"column":2},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":2,"column":4}},{"generated":{"line":8,"column":6},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":2,"column":8}},{"generated":{"line":8,"column":8},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":2,"column":10}},{"generated":{"line":8,"column":37},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":1,"column":31}},{"name":"files","generated":{"line":9,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":3,"column":4}},{"name":"files","generated":{"line":9,"column":2},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":3,"column":4}},{"generated":{"line":9,"column":7},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":3,"column":9}},{"generated":{"line":9,"column":9},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":3,"column":11}},{"generated":{"line":9,"column":10},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":4,"column":8}},{"name":"name","generated":{"line":10,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":5,"column":12}},{"name":"name","generated":{"line":10,"column":4},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":5,"column":12}},{"generated":{"line":10,"column":8},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":5,"column":16}},{"generated":{"line":10,"column":10},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":5,"column":18}},{"generated":{"line":10,"column":20},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":4,"column":8}},{"name":"content","generated":{"line":11,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":6,"column":12}},{"name":"content","generated":{"line":11,"column":4},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":6,"column":12}},{"generated":{"line":11,"column":11},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":6,"column":19}},{"generated":{"line":12,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":4,"column":8}},{"generated":{"line":12,"column":3},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":3,"column":11}},{"generated":{"line":12,"column":5},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":29,"column":8}},{"name":"name","generated":{"line":13,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":30,"column":12}},{"name":"name","generated":{"line":13,"column":4},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":30,"column":12}},{"generated":{"line":13,"column":8},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":30,"column":16}},{"generated":{"line":13,"column":10},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":30,"column":18}},{"generated":{"line":13,"column":21},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":29,"column":8}},{"name":"content","generated":{"line":14,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":31,"column":12}},{"name":"content","generated":{"line":14,"column":4},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":31,"column":12}},{"generated":{"line":14,"column":11},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":31,"column":19}},{"generated":{"line":15,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":29,"column":8}},{"generated":{"line":15,"column":3},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":3,"column":11}},{"generated":{"line":15,"column":5},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":113,"column":8}},{"name":"name","generated":{"line":16,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":114,"column":12}},{"name":"name","generated":{"line":16,"column":4},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":114,"column":12}},{"generated":{"line":16,"column":8},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":114,"column":16}},{"generated":{"line":16,"column":10},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":114,"column":18}},{"generated":{"line":16,"column":20},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":113,"column":8}},{"name":"content","generated":{"line":17,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":115,"column":12}},{"name":"content","generated":{"line":17,"column":4},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":115,"column":12}},{"generated":{"line":17,"column":11},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":115,"column":19}},{"generated":{"line":18,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":113,"column":8}},{"generated":{"line":18,"column":3},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":3,"column":11}},{"generated":{"line":19,"column":0},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":1,"column":31}},{"generated":{"line":19,"column":1},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":1,"column":7}},{"name":"TicTacToeQTable","generated":{"line":21,"column":15},"source":"src/scenarios/templates/tictactoe-qtable.js","original":{"line":199,"column":15}}],"sources":{"src/scenarios/templates/tictactoe-qtable.js":"export const TicTacToeQTable = {\n    name: 'TicTacToe - Example Q-Table',\n    files: [\n        {\n            name: 'index.js',\n            content: \n`include('qtable.js');\ninclude('train.js');\n\n\nlet qtable = new QTable();\n\n\nasync function init(){\n    console.log('loading qtable');\n    await qtable.load();\n}\n\nasync function update(state, actions){\n    const action = qtable.getBestValidAction(state);\n    return action;\n}\n\nasync function finish(state, score){\n    console.log('final state: ', state);\n    console.log('score: ', score);\n}`,\n        },\n        {\n            name: 'qtable.js',\n            content:\n`class QTable{\n    constructor(initialValue = 0){\n        this._data = new Map();\n        this._initialValue = initialValue;\n    }\n    \n    stateToKey(state){\n        return state.board.flat().reduce(\n                (a,c,i) => a + c * 10**(8-i)\n            , 0);\n    }\n    \n    idToAction(id){\n        return {\n            type: \"PLACE\",\n            row: Math.floor(id / 3),\n            col: id % 3,\n            player: Player.Computer,\n        }\n    }\n    \n    actionToId(action){\n        return action.row*3 + action.col;\n    }\n    \n    set(state, action, value){\n        const key = this.stateToKey(state);\n        const actionId = this.actionToId(action);\n        if(this._data.has(key)){\n            this._data.get(key)[actionId] = value;\n        }\n        else{\n            const cols = new Array(9).fill(this._initialValue);\n            cols[actionId] = value;\n            this._data.set(key, cols);\n        }\n    }\n    \n    get(state, action = undefined){\n        const key = this.stateToKey(state);\n        if(!this._data.has(key)){\n            if(action === undefined)\n                return new Array(9).fill(this._initialValue);\n            else\n                return this._initialValue;\n        }\n        if(action === undefined){ // return full row\n            return this._data.get(key);\n        }\n        const actionId = this.actionToId(action);\n        return this._data.get(key)[actionId];\n    }\n    \n    getBestValidAction(state){\n        const actions = this.get(state).map((x,i) => [i, x]);\n        actions.sort((a,b) => b[1] - a[1]);\n    \n        let bestAction;\n        for(let i = 0; i < actions.length; i++){\n            bestAction = this.idToAction(actions[i][0]);\n            if(validAction(state, bestAction))\n                break;\n        }\n        \n        return bestAction;\n    }\n    \n    async store(name = 'qtable'){\n        await storeJson(name, this._data);\n    }\n    \n    async load(name = 'qtable'){\n        try{\n            this._data = await loadJson(name);\n        }\n        catch(e){\n            console.warn(\"no file to load!\");\n        }\n    }\n}`,\n        },\n        {\n            name: 'train.js',\n            content:\n`async function trainInit(){\n    qtable = new QTable(0);\n    return 10; // update iterations\n}\n\nasync function trainUpdate(iteration){\n    const alpha = 0.4; // learning rate\n    const gamma = 0.8; // discount factor\n    const episodes = 5000;\n    const epsilonStart = 1.0 / (iteration/2+1); // reduce random moves with iterations\n    const epsilonCoverage = 0.8; // no random moves after 80% of episodes\n    const epsilonDecline = epsilonStart / (episodes * epsilonCoverage);\n    \n    console.log(\\`training episodes: \\${episodes*iteration} - \\${episodes*(iteration+1)}\\`);\n    \n    let epsilon = epsilonStart;\n    for(let episode = 0; episode < episodes; episode++){\n        let state = {\n            board: [[0,0,0],[0,0,0],[0,0,0]],\n            player: Player.Human,\n        }\n        \n        // player starts -> random move\n        let playerActions = getActions(state);\n        let actionId = Math.round(Math.random()*(playerActions.length-1));\n        let playerAction = playerActions[actionId];\n        state = performAction(state, playerAction);\n        \n        for(let move = 0; move < 5; move++){\n            // computer turn\n            let computerAction;\n            if(Math.random() < epsilon){ // explore\n                const computerActions = getActions(state);\n                let actionId = Math.round(Math.random()*(computerActions.length-1));\n                computerAction = computerActions[actionId];\n            }\n            else{ // use qtable to get best move\n                const actions = qtable.get(state);\n                computerAction = qtable.getBestValidAction(state, 0);\n            }\n            newState = performAction(state, computerAction);\n            if(getWinner(newState) != Player.None){\n                const score = getScore(newState, Player.Computer);\n                qtable.set(state, computerAction, score);\n                break; // terminate match\n            }\n            oldState = {...state};\n            state = newState;\n            \n            // player turn -> random move\n            playerActions = getActions(state);\n            actionId = Math.round(Math.random()*(playerActions.length-1));\n            playerAction = playerActions[actionId];\n            newState = performAction(state, playerAction);\n            \n            if(getWinner(newState) != Player.None){\n                const reward = getScore(newState, Player.Computer);\n                const oldScore = qtable.get(oldState, computerAction);\n                const newScore = (1-alpha)*oldScore + alpha*reward ;\n                qtable.set(oldState, computerAction, newScore);\n                break; // terminate match\n            }\n            else{\n                const reward = getScore(newState, Player.Computer);\n                const oldScore = qtable.get(oldState, computerAction);\n                const bestNewScore = Math.max(...qtable.get(newState));\n                const newScore = (1-alpha)*oldScore + alpha*(reward + gamma*bestNewScore);\n                qtable.set(oldState, computerAction, newScore);\n                state = newState;\n            }\n        }\n        epsilon -= epsilonDecline;\n    }\n}\n\nasync function trainFinish(){\n    await qtable.store();\n    console.log('training finished!');\n}`,\n        }\n    ]\n}\n\nexport default TicTacToeQTable;"},"lineCount":null}},"error":null,"hash":"c6932e1b3353afecadb0a3fb641f398f","cacheData":{"env":{}}}